<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Ahmed Imtiaz Humayun</title>
  
  <meta name="author" content="Ahmed Imtiaz Humayun">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Ahmed Imtiaz Humayun</name>
              </p>
              <p>Hi this is Imtiaz! I am a PhD student at Rice University, where I work on understanding how data, architectures, and objectives influence the functions approximated by Deep Neural Networks (DNNs), advised by <a href="https://richb.rice.edu/">Dr. Richard Baraniuk</a>. From Aug 2023 to Dec 2024, I was a Student Researcher at <a href="https://research.google/locations/montreal/">Google Research</a>, working with teams across <em>Research, Deepmind, and Security</em>. Outside of research, I have founded <a href="#bengali-ai">Bengali.AI</a>, a non-profit that crowdsources vision-language datasets and open-sources them through benchmarking competitions, e.g., $50,000 USD Out-of-Distribution Speech Recognition Comp @ <a href="https://kaggle.com/c/bengaliai-speech">Kaggle</a>
              </p>
              <p>
                  <!-- My research interests are in understanding the effect of data (real/synthetic), objectives and architectures on Deep
Neural Networks to develop a scientific understanding of their learning dynamics. I often use the geometric
properties of functions learned by Deep Neural Networks, to explain deep learning phenomenon, characterize model
behavior and (self-)improve their downstream performance. -->
                Deep neural networks are commonly used as universal function approximators where individual neurons learn to induce changes/non-liniearities in the function being learned. My research involves studying how the local geometry of non-linearities in the learned functions relate to memorization, generalization, biases, and robustness in DNNs. Our work has broad implications across domains, e.g., in interpreting/explaining DNN phenomenon, model auditing, providing provable robustness/safety guarantees and even prediciting downstream behavior of generative models for a given prompt/latent. Apart from this I like thinking about synthetic data training and how it can be used to obtain desired properties in DNN functions.
                <br>
                <br>  
                  I am a recepient of the Lowernstein Fellowship at Rice. My work has been published at NeurIPS, ICML, ICLR, CVPR, ICASSP and INTERSPEECH to name a few, and has been featured in multiple news sources, e.g., <a href="https://www.nytimes.com/interactive/2024/08/26/upshot/ai-synthetic-data.html">The New York Times</a>, <a href="https://cacm.acm.org/news/training-neural-networks-to-grok/">Communications of the ACM</a>, <a href="https://www.telegraph.co.uk/business/2024/02/01/why-ai-new-age-of-fake-news-and-disinformation/">The Telegraph</a>, <a href="https://finance.yahoo.com/news/ais-mad-cow-disease-problem-tramples-into-earnings-season-100005953.html?guccounter=1">yahoo!finance</a>, <a href="https://fortune.com/2024/04/18/linkedin-microsoft-collaborative-articles-generative-ai-feedback-loop-user-backlash/?456789">FORTUNE</a>, <a href="https://wired.me/technology/synthetic-data-harm-ai/">WIRED</a>, <a href="https://www.newscientist.com/article/2382519-ais-trained-on-ai-generated-images-produce-glitches-and-blurs/">New Scientist</a>, <a href="https://futurism.com/ai-trained-ai-generated-data">Futurism</a>, <a href="https://www.tomshardware.com/news/generative-ai-goes-mad-when-trained-on-artificial-data-over-five-times">Tom's Hardware</a>, <a href="https://www.thedailystar.net/tech-startup/news/meet-the-bengali-ai-3172446">The Daily Star</a>, <a href="https://www.tbsnews.net/features/panorama/bengaliai-democratising-ai-research-bangla-556458">The Business Standard</a>, <a href="https://drive.google.com/file/d/1etkJz1PbK7sYe789u9R5JzH1OlJtl3nA/view?usp=sharing">Prothom Alo</a> (Bengali), and <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7974869">IEEE Signal Processing Magazine</a>.
                
              </p>
              <p style="text-align:center">
                <a href="mailto:ahmed.imtiaz.prio@gmail.com">Email</a> &nbsp/&nbsp
                <a href="./Imtiaz_Humayun_CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=wJ2HUn4AAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/imtiazprio">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/AhmedImtiazPrio">Github</a>
                <!-- <a href="https://people.bengali.ai/imtiaz/">Old Website</a> -->
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/imtiaz_square.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/imtiaz_square.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                My research transects the domains of deep learning theory, generative modeling, interpretability, and optimization. Some of my representative projects are listed below. 
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

	    <tr bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/dynamics.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="./grokking/index.html">
                <papertitle>Deep Networks Always Grok and Here is Why</papertitle>
              </a>
              <br>
              <strong>Ahmed Imtiaz Humayun</strong>,
              <a href="https://scholar.google.com/citations?user=S1x_xqcAAAAJ&hl=en">Randall Balestriero</a>,
              <a href="https://richb.rice.edu/">Richard Baraniuk</a>
              <br>
              <em>ICML 2024</em>
              <br>
              <a href="./grokking/index.html">website</a>
        /
              <a href="https://github.com/AhmedImtiazPrio/grok-adversarial">codes</a>
        /
              <a href="https://arxiv.org/abs/2402.15555">arXiv</a>
              <p></p>
              <p>We show that Grokking, a perplexing phenomenon in deep neural networks (DNNs), manifests for adversarial examples across various practical settings like Resnets on Imagenette and GPT on Shakespeare Text. The emergence of delayed generalization and robustness is explained by a phase change in a DNN's mapping geometry, when a robust partitioning of the input space by the DNN emerges.</p>
            </td>
          </tr>

            <!-- What Secrets Do Your Manifolds Hold? Understanding the Local Geometry of Generative Models
Download PDF
Ahmed Imtiaz Humayun, Ibtihel Amara, Cristina Nader Vasconcelos, Deepak Ramachandran, Candice Schumann, Junfeng He, Katherine A Heller, Golnoosh Farnadi, Negar Rostamzadeh, Mohammad Havaei 
27 Sept 2024 (modified: 02 Dec 2024)ICLR 2025 Conference SubmissionEveryoneRevisionsBibTeXCC BY 4.0
Keywords: Geometry, Diffusion models, VAE, Generative Models, Guidance, Memorization, Out-of-Distribution Detection
TL;DR: We show that the local geometry of generative models is indicative of generation aesthetics, artifacts, diversity, and memorization.
Abstract:
Deep Generative Models are frequently used to learn continuous representations of complex data distributions using a finite number of samples. For any generative model, including pre-trained foundation models with GAN, Transformer or Diffusion architectures, generation performance can vary significantly based on which part of the learned data manifold is sampled. In this paper we study the post-training local geometry of the learned manifold and its relationship to generation outcomes for models ranging from toy settings to the latent decoder of the near state-of-the-art Stable Diffusion 1.4 Text-to-Image model. Building on the theory of continuous piecewise-linear (CPWL) generators, we characterize the local geometry in terms of three geometric descriptors - scaling (
), rank (
), and complexity (
). We provide quantitative and qualitative evidence showing that for a given latent, the local descriptors are indicative of generation aesthetics, artifacts, diversity, and memorization. Finally we demonstrate that training a reward model using the local geometry allows us to control the log-likelihood of a generated sample under the learned distribution, and improve the qualitative aspects of an image. -->
            
	    <tr bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/manifold_secrets.webp' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://openreview.net/pdf?id=etif9j1CnG">
                <papertitle>What Secrets Do Your Manifolds Hold? Understanding the Local Geometry of Generative Models</papertitle>
              </a>
              <br>
              <strong>Ahmed Imtiaz Humayun</strong>,
                <a href="#">Ibtihel Amara</a>,
                <a href="#">Cristina Nader Vasconcelos</a>,
                <a href="#">Deepak Ramachandran</a>,
                <a href="#">Candice Schumann</a>,
                <a href="#">Junfeng He</a>,
                <a href="#">Katherine Heller</a>,
                <a href="#">Golnoosh Farnadi</a>,
                <a href="#">Negar Rostamzadeh</a>,
                <a href="#">Mohammad Havaei</a>
              <br>
              <em>Arxiv 2024</em>
              <br>
              <!-- <a href="./grokking/index.html">website</a>
        / -->
              <!-- <a href="https://github.com/AhmedImtiazPrio/grok-adversarial">codes</a>
        / -->
              <a href="https://openreview.net/pdf?id=etif9j1CnG">arXiv</a>
              <p></p>
              <p>We provide quantitative and qualitative evidence showing that for models ranging from toy settings to foundational Text-to-Image models like Stable Diffusion 1.4 and DiT-XL, the local geometry of the generator mapping is indicative of downstream generation aesthetics, diversity, and memorization. Finally we demonstrate that by training a reward model on the local geometry, we can guide generation to increase the diversity and human preference score of samples.</p>
            </td>
          </tr>
		
         
<!--             <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/dynamics.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://arxiv.org/abs/2307.01850">
                <papertitle>Training Dynamics of Deep Network Linear Regions</papertitle>
              </a>
              <br>
              <strong>Ahmed Imtiaz Humayun</strong>,
              <a href="randallbalestriero.github.io">Randall Balestriero</a>,
              <a href="https://richb.rice.edu/">Richard Baraniuk</a>
              <br>
        <em>ArXiv 2023</em>
              <br>
              <a href="https://arxiv.org/abs/2310.12977">arXiv</a>
              <p></p>
              <p>We present empirical evidence showing that the local complexity of DNNs -- measured in terms of linear region density -- undergro an epoch-wise double descent phenomenon during training. Starting with an initial descend phase, after a number of epochs the network accumulates its non-linearities around training points, resulting in a ascent of local complexity. Finally through another descent phase, all the non-linearities of the networks accumulate around the decision boundary.</p>
            </td>
          </tr> -->


            <!-- Learning Transferable Features for Implicit Neural Representations
K Vyas, AI Humayun, A Dashpute, R Baraniuk, A Veeraraghavan, G Balakrishnan
TL;DR: Novel shared encoder architecture to make the coarse geometry of functions learned by INRs transferrable.
NeurIPS 2024 -->

             <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/strainer_init.webp' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://kushalvyas.github.io/strainer.html">
                <papertitle>Learning Transferable Features for Implicit Neural Representations</papertitle>
              </a>
              <br>
              <a href="#">Kushal Vyas</a>,
              <strong>Ahmed Imtiaz Humayun</strong>,
              <a href="#">Aniket Dashpute</a>,
              <a href="#">Richard Baraniuk</a>,
            <a href="#">Ashok Veeraraghavan</a>,
            <a href="#">Guha Balakrishnan</a>
              <br>
        <em>NeurIPS 2024</em>
              <br>
              <a href="https://arxiv.org/abs/2409.09566">arXiv</a>
              /
              <a href="https://colab.research.google.com/drive/1fBZAwqE8C_lrRPAe-hQZJTWrMJuAKtG2?usp=sharing">colab</a>
                /
              <a href="https://kushalvyas.github.io/strainer.html">website</a>
              <p></p>
              <p>For low dimensional regression tasks such as fitting implicit neural representations on 2D/3D signals, we present a simple pre-training method requiring only 10 regression tasks/signals, to obtain weight initializations that always results in faster convergence upon fine-tuning.</p>
            </td>
          </tr>
            
<!-- Rethinking Sparse Scaling Through the Lens of Average Parameter Count
T Jin, AI Humayun, U Evci, S Subramanian, A Yazdanbakhsh, D Alistarh, GK Dziugaite
TL;DR: Novel scaling laws and pruning routines for sparse pre-training achieving iso-FLOP performance as dense pre-training.
Under Review 2024 [url] -->
            <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/sparse_pretraining.webp' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://openreview.net/forum?id=ud8FtE1N4N">
                <papertitle>Rethinking Sparse Scaling Through the Lens of Average Parameter Count</papertitle>
              </a>
              <br>
              <a href="#">Tian Jin</a>,
              <strong>Ahmed Imtiaz Humayun</strong>,
              <a href="#">Utku Evci</a>,
              <a href="#">Suvinay Subramanian</a>,
            <a href="#">Amir Yazdanbakhsh</a>,
            <a href="#">Dan Alistarh</a>,
            <a href="#">Gintare Karolina Dziugaite</a>
              <br>
        <em>ArXiv 2024</em>
              <br>
              <a href="https://openreview.net/forum?id=ud8FtE1N4N">arXiv</a>
              <!-- / -->
              <!-- <a href="#">codes</a> -->
              <p></p>
              <p>We adapt current scaling laws with the average active parameter count to obtain scaling laws for sparse pre-training. We also present pruning routines for sparse pre-training that achieves the same performance as dense pre-training for a fixed FLOP budget. This results in significant reductions in inference compute.</p>
            </td>
          </tr>

            
<!-- Self-Improving Diffusion Models using Synthetic Data
S Alemohammad, AI Humayun, S Agarwal, J Collomosse, R Baraniuk
TL;DR: Achieve SOTA generation for diffusion models using only their synthetic data; also mitigates model collapse.
Arxiv 2024 -->
            <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/sims.jpg' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://arxiv.org/abs/2408.16333">
                <papertitle>Self-Improving Diffusion Models using Synthetic Data</papertitle>
              </a>
              <br>
              <a href="#">Sina Alemohammad</a>,
              <strong>Ahmed Imtiaz Humayun</strong>,
              <a href="#">Shruti Agarwal</a>,
              <a href="#">John Collomosse</a>,
              <a href="https://richb.rice.edu/">Richard Baraniuk</a>
              <br>
        <em>ArXiv 2024</em>
              <br>
              <a href="https://arxiv.org/abs/2408.16333">arXiv</a>
              <!-- / -->
              <!-- <a href="#">codes</a> -->
              <p></p>
                <!-- Achieve SOTA generation for diffusion models using only their synthetic data; also mitigates model collapse. -->
              <p>We present a novel algorithm for self-improving diffusion models using their own generated samples. By, fine-tuning a base model on its own synthetic data, we obtain a collapsed/MAD score function, that we use to negatively guide generation for the base model. This results in mitigation of model collapse and (self-)improvement of generation performance (FID).</p>
            </td>
          </tr>
          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/selfconsume.jfif' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://arxiv.org/abs/2307.01850">
                <papertitle>Self-consuming Generative Models go MAD</papertitle>
              </a>
              <br>
              <a href="#">Sina Alemohammad*</a>,
              <a href="#">Josue Casco-Rodriguez*</a>,
              <a href="#">Lorenzo Luzi</a>,
              <strong>Ahmed Imtiaz Humayun</strong>,
              <a href="#">Hossain Babaei</a>,
              <a href="#">Daniel Lejeune</a>,
              <a href="#">Ali Siahkoohi</a>,
              <a href="https://richb.rice.edu/">Richard Baraniuk</a>
              <br>
        <em>ICLR 2024</em>
              <br>
              <a href="https://arxiv.org/abs/2307.01850">arXiv</a>
              /
              <a href="https://futurism.com/ai-trained-ai-generated-data">news</a>
              <p></p>
              <p>We study the phenomenon of training new generative models with synthetic data from previous generative models. Our primary conclusion is that without enough fresh real data in each generation of a self-consuming or autophagous loop, future generative models are doomed to have their quality (precision) or diversity (recall) progressively decrease.</p>
            </td>
          </tr>

		 <tr bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/exact_viz.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="./splinecam/index.html">
                <papertitle>SplineCam: Exact Visualization and Characterization of Deep Network Geometry and Decision Boundary</papertitle>
              </a>
              <br>
              <strong>Ahmed Imtiaz Humayun</strong>,
              <a href="https://scholar.google.com/citations?user=S1x_xqcAAAAJ&hl=en">Randall Balestriero</a>,
              <a href="https://guha.rice.edu/">Guha Balakrishnan</a>,
              <a href="https://richb.rice.edu/">Richard Baraniuk</a>
              <br>
              <em>CVPR</em> <font color="red"><strong>(Highlight)</strong></font>, 2023
              <br>
              <a href="./splinecam/index.html">website</a>
        /
              <a href="https://github.com/AhmedImtiazPrio/splinecam">codes</a>
        /
              <a href="https://arxiv.org/abs/2302.12828">arXiv</a>
              <p></p>
              <p>The first provably exact method for computing the geometry of ANY DNN's mapping, including its decision boundary. For a specified region of the input space, SplineCam can be used to compute and visualize the 'linear regions' formed by any DNN with piecewise linear non-linearities, e.g., LeakyReLU, Sawtooth.</p>
            </td>
          </tr>
	 
	<tr>

		
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/proRobust.png' width="150">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="./splinecam/index.html">
                <papertitle>Provable Instance Specific Robustness via Linear Constraints</papertitle>
              </a>
              <br>
              <strong>Ahmed Imtiaz Humayun*</strong>,
              <a href="#">Josue Casco-Rodriguez*</a>,
              <a href="https://scholar.google.com/citations?user=S1x_xqcAAAAJ&hl=en">Randall Balestriero</a>,
              <a href="https://richb.rice.edu/">Richard Baraniuk</a>
              <br>
        <em>ICML 2023 AdvML Workshop</em>
              <br>
              <a href="./splinecam/index.html">website</a>
        /
              <a href="#">arXiv (coming soon)</a>
              <p></p>
              <p>Using spline theory, we present a novel method for imposing analytical constraints directly on the decision boundary for provable robustness. Our method can provably ensure robustness for any set of instances, e.g. training samples from a specific class, against adversarial, backdoor or poisoning attack.</p>
            </td>
          </tr>
          




          <tr bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/polarity.PNG' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://arxiv.org/abs/2203.01993">
                <papertitle>Polarity Sampling: Quality and Diversity Control of Pre-Trained Generative Networks via Singular Values</papertitle>
              </a>
              <br>
              <strong>Ahmed Imtiaz Humayun</strong>,
              <a href="https://scholar.google.com/citations?user=S1x_xqcAAAAJ&hl=en">Randall Balestriero</a>,
              <a href="https://richb.rice.edu/">Richard Baraniuk</a>
              <br>
        <em>CVPR</em> <font color="red"><strong>(Oral Presentation)</strong></font>, 2022
              <br>
              <a href="https://github.com/AhmedImtiazPrio/magnet-polarity">codes</a>
        /
              <a href="https://arxiv.org/abs/2203.01993">arXiv</a>
        /
              <a href="https://www.youtube.com/watch?v=zRKyx_dF89M">video</a>
              <p></p>
              <p>A provable method for controllable generation based on quality and diversity from any pre-trained deep generative model. We show that increasing the sampling diversity helps surpass SOTA image generation.</p>
            </td>
          </tr>

          <tr bgcolor="#ffffd0" onmouseout="magnet_stop()" onmouseover="magnet_stop()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='blocknerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/magnet_draft.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/magnet_draft_still.png' width="160">
              </div>
              <script type="text/javascript">
                function magnet_start() {
                  document.getElementById('blocknerf_image').style.opacity = "1";
                }

                function magnet_stop() {
                  document.getElementById('blocknerf_image').style.opacity = "0";
                }
                magnet_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://arxiv.org/abs/2110.08009">
                <papertitle>MaGNET: Uniform Sampling from Deep Generative Network Manifolds Without Retraining</papertitle>
              </a>
              <br>
              <strong>Ahmed Imtiaz Humayun</strong>,
              <a href="https://scholar.google.com/citations?user=S1x_xqcAAAAJ&hl=en">Randall Balestriero</a>,
              <a href="https://richb.rice.edu/">Richard Baraniuk</a>
              <br>
        <em>ICLR</em>, 2022
              <br>
              <a href="https://github.com/AhmedImtiazPrio/MaGNET">codes</a>
        /
              <a href="https://arxiv.org/abs/2110.08009">arXiv</a>
        /
              <a href="https://www.youtube.com/watch?v=0Muk7nKzOW8">video</a>
              <p></p>
              <p> A novel and theoretically motivated latent space sampler for any pre-trained DGN, that produces samples uniformly distributed on the learned output manifold. Applications in fairness and data augmentation.</p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/dec_boundary.jpg' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="./splinecam/index.html">
                <papertitle>Exact Visualization of Deep Neural Network Geometry and Decision Boundary</papertitle>
              </a>
              <br>
              <strong>Ahmed Imtiaz Humayun</strong>,
              <a href="https://scholar.google.com/citations?user=S1x_xqcAAAAJ&hl=en">Randall Balestriero</a>,
              <a href="https://richb.rice.edu/">Richard Baraniuk</a>
              <br>
        <em>NeurIPS 2022 Workshop on Symmetry and Geometry (NeurReps)</em>
              <br>
              <a href="./splinecam/index.html">website</a>
        /
              <a href="https://openreview.net/forum?id=VSLbmsoZxai">arXiv</a>
        /
              <a href="./splinecam/neurreps_poster.pdf">poster</a>
              <p></p>
              <p>Using spline theory, we present a method for exact visualization of deep neural networks that allows us to visualize the decision boundary and also sample arbitrarily many inputs that provably lie on the model's decision boundary </p>
            </td>
          </tr>



          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/rcons.PNG' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://arxiv.org/abs/2203.02502">
                <papertitle>No More Than 6ft Apart: Robust K-Means via Radius Upper Bounds</papertitle>
              </a>
              <br>
              <strong>Ahmed Imtiaz Humayun</strong>,
              <a href="https://scholar.google.com/citations?user=S1x_xqcAAAAJ&hl=en">Randall Balestriero</a>,
              <a href="https://akyrillidis.github.io/">Anastasios Kyrillidis</a>,
              <a href="https://richb.rice.edu/">Richard Baraniuk</a>
              <br>
        <em>ICASSP</em>, 2022
              <br>
              <a href="https://github.com/AhmedImtiazPrio/radius-constrained-kmeans">codes</a>
        /
              <a href="https://arxiv.org/abs/2203.02502">arXiv</a>
              <p></p>
              <p>Repeated samples and sampling bias may manifest imbalanced clustering via K-methods. We propose the first method to impose a hard radius constraint on K-Means, achieving robustness towards sampling inconsistencies.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/MASK.jpg' width="140">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://arxiv.org/abs/2010.13975">
                <papertitle>Compressed Representations of Variable-Length Sequences Using Recurrent Neural Tangent Kernels</papertitle>
              </a>
              <br>
              <a href="#">S Alemohammad</a>,
              <a href="#">H Babaei</a>,
              <a href="#">R Balestriero</a>,
              <a href="#">MY Cheung</a>,
              <strong>Ahmed Imtiaz Humayun</strong>,
              <a href="#">D Lejeune</a>,
              <a href="#">L Luzi</a>,
              <a href="https://richb.rice.edu/">Richard Baraniuk</a>
              <br>
        <em>ICASSP</em>, 2021
              <br>
              <a href="https://github.com/dlej/MASK">codes</a>
        /
              <a href="https://arxiv.org/abs/2010.13975">arXiv</a>
              <p></p>
              <p>We extend existing methods that rely on the use of kernels to variable-length sequences by using the Recurrent Neural Tangent Kernel (RNTK).</p>
            </td>
          </tr>

          <tr bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/domainInvHeartsound.png' width="140">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://arxiv.org/abs/1910.00498">
                <papertitle>Towards Domain Invariant Heart Sound Abnormality Detection using Learnable Filterbanks</papertitle>
              </a>
              <br>
              <strong>Ahmed Imtiaz Humayun</strong>,
              <a href="https://scholar.google.com/citations?user=LGI2QXoAAAAJ&hl=en">Shabnam Gaffarzadegan</a>,
              <a href="https://scholar.google.com/citations?user=zXta31UAAAAJ&hl=en">Zhe Feng</a>,
              <a href="https://scholar.google.com/citations?user=Utz82Y4AAAAJ&hl=en">Taufiq Hasan</a>
              <br>
        <em>IEEE JBHI</em>, 2020
              <br>
              <a href="https://github.com/AhmedImtiazPrio/heartnet">codes</a>
        /
              <a href="https://arxiv.org/abs/1910.00498">arXiv</a>
              <p></p>
              <p>We show that novel Convolutional Neural Network (CNN) layers that emulate different classes of Finite Impulse Response (FIR) filters can perform domain invariant heart sound abnormality detection.</p>
            </td>
          </tr>
					
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/sleep.jpg' width="140">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://arxiv.org/abs/1904.10255">
                <papertitle>End-to-end Sleep Staging with Raw Single Channel EEG using Deep Residual ConvNets</papertitle>
              </a>
              <br>
              <strong>Ahmed Imtiaz Humayun</strong>,
              <a href="#">Asif Sushmit</a>,
              <a href="https://scholar.google.com/citations?user=Utz82Y4AAAAJ&hl=en">Taufiq Hasan</a>,
              <a href="#">MIH Bhuiyan</a>
              <br>
        <em>IEEE BHI</em>, 2019
              <br>
              <a href="https://github.com/AhmedImtiazPrio/ASSC">codes</a>
        /
              <a href="https://arxiv.org/abs/1904.10255">arXiv</a>
              <p></p>
              <p>Very Deep Convolutional Residual Network achieve state-of-the-art results in sleep staging, using only raw single channel EEG.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/xrayImgComp.jpg' width="140">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://ieeexplore.ieee.org/document/8834656">
                <papertitle>X-Ray Image Compression Using Convolutional Recurrent Neural Networks</papertitle>
              </a>
              <br>
              <a href="#">Asif Sushmit</a>,
              <a href="#">SU Zaman</a>,
              <strong>Ahmed Imtiaz Humayun</strong>,
              <a href="https://scholar.google.com/citations?user=Utz82Y4AAAAJ&hl=en">Taufiq Hasan</a>,
              <a href="#">MIH Bhuiyan</a>
              <br>
        <em>IEEE BHI</em>, 2019
              <br>
              <a href="mailto:sushmit0109@gmail.com ">codes</a>
        /
              <a href="https://ieeexplore.ieee.org/document/8834656">paper</a>
              <p></p>
              <p>Convolutional Recurrent Neural Networks outperform SOTA RNN based compression methods as well as JPEG 2000 for X-ray image compression.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/filterbank.jpg' width="140">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://www.isca-speech.org/archive/interspeech_2018/humayun18_interspeech.html">
                <papertitle>An Ensemble of Transfer, Semi-supervised and Supervised Learning Methods for Pathological Heart Sound Classification</papertitle>
              </a>
              <br>
              <strong>Ahmed Imtiaz Humayun</strong>,
              <a href="#">MT Khan</a>,
              <a href="https://scholar.google.com/citations?user=LGI2QXoAAAAJ&hl=en">Shabnam Gaffarzadegan</a>,
              <a href="https://scholar.google.com/citations?user=zXta31UAAAAJ&hl=en">Zhe Feng</a>,
              <a href="https://scholar.google.com/citations?user=Utz82Y4AAAAJ&hl=en">Taufiq Hasan</a>
              <br>
        <em>INTERSPEECH</em>, 2018
              <br>
              <a href="https://github.com/AhmedImtiazPrio/heartnet">codes</a>
        /
              <a href="https://arxiv.org/abs/1806.06506">arXiv</a>
              <p></p>
              <p>State-of-the-art heart abnormality classification using an ensemble of Representation Learning methods.</p>
            </td>
          </tr>

          <tr bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/learned_params.jpg' height="140">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://arxiv.org/abs/1806.05892">
                <papertitle>Learning Front-end Filter-bank Parameters using Convolutional Neural Networks for Abnormal Heart Sound Detection</papertitle>
              </a>
              <br>
              <strong>Ahmed Imtiaz Humayun</strong>,
              <a href="https://scholar.google.com/citations?user=LGI2QXoAAAAJ&hl=en">Shabnam Gaffarzadegan</a>,
              <a href="https://scholar.google.com/citations?user=zXta31UAAAAJ&hl=en">Zhe Feng</a>,
              <a href="https://scholar.google.com/citations?user=Utz82Y4AAAAJ&hl=en">Taufiq Hasan</a>
              <br>
        <em>IEEE EMBC</em>, 2018
              <br>
              <a href="https://github.com/AhmedImtiazPrio/heartnet">codes</a>
        /
              <a href="https://arxiv.org/abs/1806.05892">arXiv</a>
              <p></p>
              <p>We propose novel linear phase and zero phase convolutional neural networks that can be used as learnable filterbank front-ends.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/spcup.png' height="140">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://ieeexplore.ieee.org/document/8397024">
                <papertitle>Predictive Real-time Beat Tracking from Music for Embedded Application</papertitle>
              </a>
              <br>
              <a href="#">Irfan Hussaini</a>,
              <strong>Ahmed Imtiaz Humayun</strong>,
              <a href="#">Shariful Foysal</a>,
              <a href="#">Samiul Alam</a>,
              <a href="#">Ahmed Masud</a>,
              <a href="#">Rakib Hyder</a>,
              <a href="#">SS Chowdhury</a>,
              <a href="#">MA Haque</a>
              <br>
        <em>IEEE MIPR</em>, 2018
              <br>
              <a href="https://github.com/AhmedImtiazPrio/RTBT">codes</a>
        /
              <a href="https://ieeexplore.ieee.org/document/8397024">paper</a>
        /
              <a href="https://www.youtube.com/watch?v=fyENs0ABZhw&feature=youtu.be">video</a>
              <p></p>
              <p>IEEE Signal Processing Cup Honorable Mention for Real-time Music Beat Tracking Embedded System.</p>
            </td>
          </tr>
        
          <table id="bengali-ai" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Bengali.AI</heading>
              <p>
                <a href="www.bengali.ai">Bengali.AI</a> is a non-profit in Bangladesh where we create novel datasets to accelerate Bengali Language Technologies (e.g., OCR, ASR) and open-source them through machine learning competitions (e.g., <a href="https://www.kaggle.com/c/bengaliai-cv19">Grapheme 2020</a>, <a href="https://www.kaggle.com/competitions/dlsprint">ASR 2022</a>)
              </p>
            </td>
          </tr>
        </tbody></table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/ood_speech.jpg' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://arxiv.org/abs/2305.09688">
                <papertitle>OOD-Speech: A Large Bengali Speech Recognition Dataset for Out-of-Distribution Benchmarking</papertitle>
              </a>
              <br>
              <a href="">FR Rakib</a>,
              <a href="">SS Dip</a>,
              <a href="">S Alam</a>,
              <a href="">N Tasnim</a>,
              <a href="">MIH Shihab</a>,
              <a href="">+ 5 authors</a>,
              <a href="">Farig Sadeque</a>,
              <a href="">Tahsin Reasat</a>,
              <a href="">AS Sushmit</a>,
              <strong>Ahmed Imtiaz Humayun</strong>
              <br>
        <em>INTERSPEECH</em>, 2023
              <br>
              <a href="https://kaggle.com/c/bengaliai-speech">competition</a>
        /
              <a href="https://arxiv.org/abs/2305.09688">arXiv</a>
              <p></p>
              <p>Jointly largest open-sourced Bengali ASR dataset as well as first Bengali Out-of-Distribution Speech Recognition benchmarking dataset.</p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/badlad.jpg' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://arxiv.org/abs/2303.05325">
                <papertitle>BaDLAD: A Large Multi-Domain Bengali Document Layout Analysis Dataset</papertitle>
              </a>
              <br>
              <a href="">MIH Shihab</a>,
              <a href="">MR Hassan</a>,
              <a href="">M Rahman</a>,
              <a href="">SM Hossen</a>,
              <a href="">+11 authors</a>,
              <a href="">AS Sushmit*</a>,
              <strong>Ahmed Imtiaz Humayun*</strong>
              <br>
        <em>ICDAR</em>, 2023
              <br>
              <a href="https://www.kaggle.com/datasets/reasat/badlad-train/">dataset</a>
        /
              <a href="https://arxiv.org/abs/2303.05325">arXiv</a>
        /
              <a href="https://kaggle.com/c/dlsprint2">competition</a>
              <p></p>
              <p>First Multi-Domain Bengali Document Layout Analysis Dataset, with 700K polygon annotations from image captured documents in the wild.</p>
            </td>
          </tr>




          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/dlsprint.jpg' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://arxiv.org/pdf/2206.14053">
                <papertitle>Bengali Common Voice Speech Dataset for Automatic Speech Recognition</papertitle>
              </a>
              <br>
              <a href="">Samiul Alam</a>,
              <a href="">Asif Sushmit</a>,
              <a href="">Zaowad Abdullah</a>,
              <a href="">Shahrin Nakkhatra</a>,
              <a href="">MD Ansary</a>,
              <a href="">Syed Hossen</a>,
              <a href="">Sazia Mehnaz</a>,
              <a href="">Tahsin Reasat</a>,
              <strong>Ahmed Imtiaz Humayun</strong>
              <br>
        <em>ArXiv</em>, 2022
              <br>
              <a href="https://www.kaggle.com/competitions/dlsprint">competition</a>
        /
              <a href="https://arxiv.org/pdf/2206.14053">arXiv</a>
              <p></p>
              <p>We have crowdsourced the first public 500 hr Bengali Speech Dataset on the Mozilla Common Voice platform, with speech contributed by over 20K people from Bangladesh and India.</p>
            </td>
          </tr>
          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/grapheme.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://www.kaggle.com/c/bengaliai-cv19">
                <papertitle>A Large Multi-Target Dataset of Common Bengali Handwritten Graphemes</papertitle>
              </a>
              <br>
              <a href="">Samiul Alam</a>,
              <a href="">Tahsin Reasat</a>,
              <a href="">Asif Sushmit</a>,
              <a href="">SM Siddiquee</a>,
              <a href="">Fuad Rahman</a>,
              <a href="">Mahady Hasan</a>,
              <strong>Ahmed Imtiaz Humayun</strong>
              <br>
        <em>ICDAR</em>, 2021
              <br>
              <a href="https://www.kaggle.com/c/bengaliai-cv19">competition</a>
        /
              <a href="https://arxiv.org/pdf/2010.00170">arXiv</a>
        /
              <a href="https://www.technology.org/2019/12/31/bengali-ai-handwritten-grapheme-classification/">news</a>
              <p></p>
              <p>A benchmark datset for multi-target classification of handwritten Bengali Graphemes, with novel implications for all alpha-syllabary languages, e.g., Hindi, Gujrati, and Thai.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/numta.gif' width="140">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://www.kaggle.com/c/numta">
                <papertitle>NumtaDB: Assembled Bengali Handwritten Digits</papertitle>
              </a>
              <br>
              <a href="">Samiul Alam</a>,
              <a href="">Tahsin Reasat</a>,
              <a href="">Rashed Doha</a>,
              <strong>Ahmed Imtiaz Humayun</strong>
              <br>
        <em>ArXiv</em>, 2018
              <br>
              <a href="https://www.kaggle.com/c/numta">competition</a>
        /
              <a href="https://arxiv.org/pdf/1806.02452">arXiv</a>
              <p></p>
              <p>The first large scale Multi-Domain Bengali Handwritten Digit Recognition Dataset</p>
            </td>
          </tr>


          </tbody></table>

        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Yet another steal of <a href="https://jonbarron.info/">Jon Barron's</a> amazing website.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
