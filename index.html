<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Ahmed Imtiaz Humayun</title>
  
  <meta name="author" content="Ahmed Imtiaz Humayun">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Ahmed Imtiaz Humayun</name>
              </p>
              <p>I am a PhD student at <a href="https://dsp.rice.edu/">Rice University</a>, where I work on deep learning theory and generative modeling, advised by Dr. Richard Baraniuk.
              </p>
              <p>
                My interests lie in interpretation and improvement of deep neural network models via approximation theory, e.g., spline theory. I have received the Lowernstein Fellowship at Rice and have published in ICLR, CVPR, ICASSP, and INTERSPEECH, to name a few. I have also founded <a href="#bengali-ai">Bengali.AI</a>, a non-profit initiative that crowdsources datasets and open-sources them through international ML competitions, e.g., Out-of-Distribution Speech Recognition @ <a href="https://kaggle.com/c/bengaliai-speech">Kaggle</a>.
                <br>
                <br>
                My work has been featured in multiple news sources, e.g., <a href="https://www.newscientist.com/article/2382519-ais-trained-on-ai-generated-images-produce-glitches-and-blurs/">New Scientist</a>, <a href="https://futurism.com/ai-trained-ai-generated-data">Futurism</a>, <a href="https://www.tomshardware.com/news/generative-ai-goes-mad-when-trained-on-artificial-data-over-five-times">Tom's Hardware</a>, <a href="https://www.thedailystar.net/tech-startup/news/meet-the-bengali-ai-3172446">The Daily Star</a>, <a href="https://www.tbsnews.net/features/panorama/bengaliai-democratising-ai-research-bangla-556458">The Business Standard</a> and <a href="https://drive.google.com/file/d/1etkJz1PbK7sYe789u9R5JzH1OlJtl3nA/view?usp=sharing">Prothom Alo (Bengali)</a>.
                
              </p>
              <p style="text-align:center">
                <a href="mailto:ahmed.imtiaz.prio@gmail.com">Email</a> &nbsp/&nbsp
                <a href="./Imtiaz_Humayun_CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=wJ2HUn4AAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/imtiazprio">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/AhmedImtiazPrio">Github</a>
                <!-- <a href="https://people.bengali.ai/imtiaz/">Old Website</a> -->
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/imtiaz_square.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/imtiaz_square.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                My research transects the domains of deep learning theory, generative modeling, interpretability, and optimization. Some of my representative projects are listed below. 
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/exact_viz.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="./splinecam/index.html">
                <papertitle>SplineCam: Exact Visualization and Characterization of Deep Network Geometry and Decision Boundary</papertitle>
              </a>
              <br>
              <strong>Ahmed Imtiaz Humayun</strong>,
              <a href="https://scholar.google.com/citations?user=S1x_xqcAAAAJ&hl=en">Randall Balestriero</a>,
              <a href="https://guha.rice.edu/">Guha Balakrishnan</a>,
              <a href="https://richb.rice.edu/">Richard Baraniuk</a>
              <br>
              <em>CVPR</em> <font color="red"><strong>(Highlight)</strong></font>, 2023
              <br>
              <a href="./splinecam/index.html">website</a>
        /
              <a href="https://github.com/AhmedImtiazPrio/splinecam">codes</a>
        /
              <a href="https://arxiv.org/abs/2302.12828">arXiv</a>
              <p></p>
              <p>The first provably exact method for computing the geometry of ANY DNN's mapping, including its decision boundary. For a specified region of the input space, SplineCam can be used to compute and visualize the 'linear regions' formed by any DNN with piecewise linear non-linearities, e.g., LeakyReLU, Sawtooth.</p>
            </td>
          </tr>

          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/selfconsume.jfif' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://arxiv.org/abs/2307.01850">
                <papertitle>Self-consuming Generative Models go MAD</papertitle>
              </a>
              <br>
              <a href="#">Sina Alemohammad*</a>,
              <a href="#">Josue Casco-Rodriguez*</a>,
              <a href="#">Lorenzo Luzi</a>,
              <strong>Ahmed Imtiaz Humayun</strong>,
              <a href="#">Hossain Babaei</a>,
              <a href="#">Daniel Lejeune</a>,
              <a href="#">Ali Siahkoohi</a>,
              <a href="https://richb.rice.edu/">Richard Baraniuk</a>
              <br>
        <em>ArXiv 2023</em>
              <br>
              <a href="https://arxiv.org/abs/2307.01850">arXiv</a>
              /
              <a href="https://futurism.com/ai-trained-ai-generated-data">news</a>
              <p></p>
              <p>We study the phenomenon of training new generative models with synthetic data from previous generative models. Our primary conclusion is that without enough fresh real data in each generation of a self-consuming or autophagous loop, future generative models are doomed to have their quality (precision) or diversity (recall) progressively decrease.</p>
            </td>
          </tr>
          

          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/proRobust.png' width="150">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="./splinecam/index.html">
                <papertitle>Provable Instance Specific Robustness via Linear Constraints</papertitle>
              </a>
              <br>
              <strong>Ahmed Imtiaz Humayun*</strong>,
              <a href="#">Josue Casco-Rodriguez*</a>,
              <a href="https://scholar.google.com/citations?user=S1x_xqcAAAAJ&hl=en">Randall Balestriero</a>,
              <a href="https://richb.rice.edu/">Richard Baraniuk</a>
              <br>
        <em>ICML 2023 AdvML Workshop</em>
              <br>
              <a href="./splinecam/index.html">website</a>
        /
              <a href="#">arXiv (coming soon)</a>
              <p></p>
              <p>Using spline theory, we present a novel method for imposing analytical constraints directly on the decision boundary for provable robustness. Our method can provably ensure robustness for any set of instances, e.g. training samples from a specific class, against adversarial, backdoor or poisoning attack.</p>
            </td>
          </tr>
          




          <tr bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/polarity.PNG' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://arxiv.org/abs/2203.01993">
                <papertitle>Polarity Sampling: Quality and Diversity Control of Pre-Trained Generative Networks via Singular Values</papertitle>
              </a>
              <br>
              <strong>Ahmed Imtiaz Humayun</strong>,
              <a href="https://scholar.google.com/citations?user=S1x_xqcAAAAJ&hl=en">Randall Balestriero</a>,
              <a href="https://richb.rice.edu/">Richard Baraniuk</a>
              <br>
        <em>CVPR</em> <font color="red"><strong>(Oral Presentation)</strong></font>, 2022
              <br>
              <a href="https://github.com/AhmedImtiazPrio/magnet-polarity">codes</a>
        /
              <a href="https://arxiv.org/abs/2203.01993">arXiv</a>
        /
              <a href="https://www.youtube.com/watch?v=zRKyx_dF89M">video</a>
              <p></p>
              <p>A provable method for controllable generation based on quality and diversity from any pre-trained deep generative model. We show that increasing the sampling diversity helps surpass SOTA image generation.</p>
            </td>
          </tr>

          <tr bgcolor="#ffffd0" onmouseout="magnet_stop()" onmouseover="magnet_stop()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='blocknerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/magnet_draft.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/magnet_draft_still.png' width="160">
              </div>
              <script type="text/javascript">
                function magnet_start() {
                  document.getElementById('blocknerf_image').style.opacity = "1";
                }

                function magnet_stop() {
                  document.getElementById('blocknerf_image').style.opacity = "0";
                }
                magnet_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://arxiv.org/abs/2110.08009">
                <papertitle>MaGNET: Uniform Sampling from Deep Generative Network Manifolds Without Retraining</papertitle>
              </a>
              <br>
              <strong>Ahmed Imtiaz Humayun</strong>,
              <a href="https://scholar.google.com/citations?user=S1x_xqcAAAAJ&hl=en">Randall Balestriero</a>,
              <a href="https://richb.rice.edu/">Richard Baraniuk</a>
              <br>
        <em>ICLR</em>, 2022
              <br>
              <a href="https://github.com/AhmedImtiazPrio/MaGNET">codes</a>
        /
              <a href="https://arxiv.org/abs/2110.08009">arXiv</a>
        /
              <a href="https://www.youtube.com/watch?v=0Muk7nKzOW8">video</a>
              <p></p>
              <p> A novel and theoretically motivated latent space sampler for any pre-trained DGN, that produces samples uniformly distributed on the learned output manifold. Applications in fairness and data augmentation.</p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/dec_boundary.jpg' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="./splinecam/index.html">
                <papertitle>Exact Visualization of Deep Neural Network Geometry and Decision Boundary</papertitle>
              </a>
              <br>
              <strong>Ahmed Imtiaz Humayun</strong>,
              <a href="https://scholar.google.com/citations?user=S1x_xqcAAAAJ&hl=en">Randall Balestriero</a>,
              <a href="https://richb.rice.edu/">Richard Baraniuk</a>
              <br>
        <em>NeurIPS 2022 Workshop on Symmetry and Geometry (NeurReps)</em>
              <br>
              <a href="./splinecam/index.html">website</a>
        /
              <a href="https://openreview.net/forum?id=VSLbmsoZxai">arXiv</a>
        /
              <a href="./splinecam/neurreps_poster.pdf">poster</a>
              <p></p>
              <p>Using spline theory, we present a method for exact visualization of deep neural networks that allows us to visualize the decision boundary and also sample arbitrarily many inputs that provably lie on the model's decision boundary </p>
            </td>
          </tr>



          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/rcons.PNG' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://arxiv.org/abs/2203.02502">
                <papertitle>No More Than 6ft Apart: Robust K-Means via Radius Upper Bounds</papertitle>
              </a>
              <br>
              <strong>Ahmed Imtiaz Humayun</strong>,
              <a href="https://scholar.google.com/citations?user=S1x_xqcAAAAJ&hl=en">Randall Balestriero</a>,
              <a href="https://akyrillidis.github.io/">Anastasios Kyrillidis</a>,
              <a href="https://richb.rice.edu/">Richard Baraniuk</a>
              <br>
        <em>ICASSP</em>, 2022
              <br>
              <a href="https://github.com/AhmedImtiazPrio/radius-constrained-kmeans">codes</a>
        /
              <a href="https://arxiv.org/abs/2203.02502">arXiv</a>
              <p></p>
              <p>Repeated samples and sampling bias may manifest imbalanced clustering via K-methods. We propose the first method to impose a hard radius constraint on K-Means, achieving robustness towards sampling inconsistencies.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/MASK.jpg' width="140">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://arxiv.org/abs/2010.13975">
                <papertitle>Compressed Representations of Variable-Length Sequences Using Recurrent Neural Tangent Kernels</papertitle>
              </a>
              <br>
              <a href="#">S Alemohammad</a>,
              <a href="#">H Babaei</a>,
              <a href="#">R Balestriero</a>,
              <a href="#">MY Cheung</a>,
              <strong>Ahmed Imtiaz Humayun</strong>,
              <a href="#">D Lejeune</a>,
              <a href="#">L Luzi</a>,
              <a href="https://richb.rice.edu/">Richard Baraniuk</a>
              <br>
        <em>ICASSP</em>, 2021
              <br>
              <a href="https://github.com/dlej/MASK">codes</a>
        /
              <a href="https://arxiv.org/abs/2010.13975">arXiv</a>
              <p></p>
              <p>We extend existing methods that rely on the use of kernels to variable-length sequences by using the Recurrent Neural Tangent Kernel (RNTK).</p>
            </td>
          </tr>

          <tr bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/domainInvHeartsound.png' width="140">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://arxiv.org/abs/1910.00498">
                <papertitle>Towards Domain Invariant Heart Sound Abnormality Detection using Learnable Filterbanks</papertitle>
              </a>
              <br>
              <strong>Ahmed Imtiaz Humayun</strong>,
              <a href="https://scholar.google.com/citations?user=LGI2QXoAAAAJ&hl=en">Shabnam Gaffarzadegan</a>,
              <a href="https://scholar.google.com/citations?user=zXta31UAAAAJ&hl=en">Zhe Feng</a>,
              <a href="https://scholar.google.com/citations?user=Utz82Y4AAAAJ&hl=en">Taufiq Hasan</a>
              <br>
        <em>IEEE JBHI</em>, 2020
              <br>
              <a href="https://github.com/AhmedImtiazPrio/heartnet">codes</a>
        /
              <a href="https://arxiv.org/abs/1910.00498">arXiv</a>
              <p></p>
              <p>We show that novel Convolutional Neural Network (CNN) layers that emulate different classes of Finite Impulse Response (FIR) filters can perform domain invariant heart sound abnormality detection.</p>
            </td>
          </tr>
					
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/sleep.jpg' width="140">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://arxiv.org/abs/1904.10255">
                <papertitle>End-to-end Sleep Staging with Raw Single Channel EEG using Deep Residual ConvNets</papertitle>
              </a>
              <br>
              <strong>Ahmed Imtiaz Humayun</strong>,
              <a href="#">Asif Sushmit</a>,
              <a href="https://scholar.google.com/citations?user=Utz82Y4AAAAJ&hl=en">Taufiq Hasan</a>,
              <a href="#">MIH Bhuiyan</a>
              <br>
        <em>IEEE BHI</em>, 2019
              <br>
              <a href="https://github.com/AhmedImtiazPrio/ASSC">codes</a>
        /
              <a href="https://arxiv.org/abs/1904.10255">arXiv</a>
              <p></p>
              <p>Very Deep Convolutional Residual Network achieve state-of-the-art results in sleep staging, using only raw single channel EEG.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/xrayImgComp.jpg' width="140">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://ieeexplore.ieee.org/document/8834656">
                <papertitle>X-Ray Image Compression Using Convolutional Recurrent Neural Networks</papertitle>
              </a>
              <br>
              <a href="#">Asif Sushmit</a>,
              <a href="#">SU Zaman</a>,
              <strong>Ahmed Imtiaz Humayun</strong>,
              <a href="https://scholar.google.com/citations?user=Utz82Y4AAAAJ&hl=en">Taufiq Hasan</a>,
              <a href="#">MIH Bhuiyan</a>
              <br>
        <em>IEEE BHI</em>, 2019
              <br>
              <a href="mailto:sushmit0109@gmail.com ">codes</a>
        /
              <a href="https://ieeexplore.ieee.org/document/8834656">paper</a>
              <p></p>
              <p>Convolutional Recurrent Neural Networks outperform SOTA RNN based compression methods as well as JPEG 2000 for X-ray image compression.</p>
            </td>
          </tr>

          <tr bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/filterbank.jpg' width="140">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://www.isca-speech.org/archive/interspeech_2018/humayun18_interspeech.html">
                <papertitle>An Ensemble of Transfer, Semi-supervised and Supervised Learning Methods for Pathological Heart Sound Classification</papertitle>
              </a>
              <br>
              <strong>Ahmed Imtiaz Humayun</strong>,
              <a href="#">MT Khan</a>,
              <a href="https://scholar.google.com/citations?user=LGI2QXoAAAAJ&hl=en">Shabnam Gaffarzadegan</a>,
              <a href="https://scholar.google.com/citations?user=zXta31UAAAAJ&hl=en">Zhe Feng</a>,
              <a href="https://scholar.google.com/citations?user=Utz82Y4AAAAJ&hl=en">Taufiq Hasan</a>
              <br>
        <em>INTERSPEECH</em>, 2018
              <br>
              <a href="https://github.com/AhmedImtiazPrio/heartnet">codes</a>
        /
              <a href="https://arxiv.org/abs/1806.06506">arXiv</a>
              <p></p>
              <p>State-of-the-art heart abnormality classification using an ensemble of Representation Learning methods.</p>
            </td>
          </tr>

          <tr bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/learned_params.jpg' height="140">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://arxiv.org/abs/1806.05892">
                <papertitle>Learning Front-end Filter-bank Parameters using Convolutional Neural Networks for Abnormal Heart Sound Detection</papertitle>
              </a>
              <br>
              <strong>Ahmed Imtiaz Humayun</strong>,
              <a href="https://scholar.google.com/citations?user=LGI2QXoAAAAJ&hl=en">Shabnam Gaffarzadegan</a>,
              <a href="https://scholar.google.com/citations?user=zXta31UAAAAJ&hl=en">Zhe Feng</a>,
              <a href="https://scholar.google.com/citations?user=Utz82Y4AAAAJ&hl=en">Taufiq Hasan</a>
              <br>
        <em>IEEE EMBC</em>, 2018
              <br>
              <a href="https://github.com/AhmedImtiazPrio/heartnet">codes</a>
        /
              <a href="https://arxiv.org/abs/1806.05892">arXiv</a>
              <p></p>
              <p>We propose novel linear phase and zero phase convolutional neural networks that can be used as learnable filterbank front-ends.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/spcup.png' height="140">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://ieeexplore.ieee.org/document/8397024">
                <papertitle>Predictive Real-time Beat Tracking from Music for Embedded Application</papertitle>
              </a>
              <br>
              <a href="#">Irfan Hussaini</a>,
              <strong>Ahmed Imtiaz Humayun</strong>,
              <a href="#">Shariful Foysal</a>,
              <a href="#">Samiul Alam</a>,
              <a href="#">Ahmed Masud</a>,
              <a href="#">Rakib Hyder</a>,
              <a href="#">SS Chowdhury</a>,
              <a href="#">MA Haque</a>
              <br>
        <em>IEEE MIPR</em>, 2018
              <br>
              <a href="https://github.com/AhmedImtiazPrio/RTBT">codes</a>
        /
              <a href="https://ieeexplore.ieee.org/document/8397024">paper</a>
        /
              <a href="https://www.youtube.com/watch?v=fyENs0ABZhw&feature=youtu.be">video</a>
              <p></p>
              <p>IEEE Signal Processing Cup Honorable Mention for Real-time Music Beat Tracking Embedded System.</p>
            </td>
          </tr>
        
          <table id="bengali-ai" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Bengali.AI</heading>
              <p>
                <a href="www.bengali.ai">Bengali.AI</a> is a non-profit in Bangladesh where we create novel datasets to accelerate Bengali Language Technologies (e.g., OCR, ASR) and open-source them through machine learning competitions (e.g., <a href="https://www.kaggle.com/c/bengaliai-cv19">Grapheme 2020</a>, <a href="https://www.kaggle.com/competitions/dlsprint">ASR 2022</a>)
              </p>
            </td>
          </tr>
        </tbody></table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/ood_speech.jpg' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://arxiv.org/abs/2305.09688">
                <papertitle>OOD-Speech: A Large Bengali Speech Recognition Dataset for Out-of-Distribution Benchmarking</papertitle>
              </a>
              <br>
              <a href="">FR Rakib</a>,
              <a href="">SS Dip</a>,
              <a href="">S Alam</a>,
              <a href="">N Tasnim</a>,
              <a href="">MIH Shihab</a>,
              <a href="">+ 5 authors</a>,
              <a href="">Farig Sadeque</a>,
              <a href="">Tahsin Reasat</a>,
              <a href="">AS Sushmit</a>,
              <strong>Ahmed Imtiaz Humayun</strong>
              <br>
        <em>INTERSPEECH</em>, 2023
              <br>
              <a href="https://kaggle.com/c/bengaliai-speech">competition</a>
        /
              <a href="https://arxiv.org/abs/2305.09688">arXiv</a>
              <p></p>
              <p>Jointly largest open-sourced Bengali ASR dataset as well as first Bengali Out-of-Distribution Speech Recognition benchmarking dataset.</p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/badlad.jpg' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://arxiv.org/abs/2303.05325">
                <papertitle>BaDLAD: A Large Multi-Domain Bengali Document Layout Analysis Dataset</papertitle>
              </a>
              <br>
              <a href="">MIH Shihab</a>,
              <a href="">MR Hassan</a>,
              <a href="">M Rahman</a>,
              <a href="">SM Hossen</a>,
              <a href="">+11 authors</a>,
              <a href="">AS Sushmit*</a>,
              <strong>Ahmed Imtiaz Humayun*</strong>
              <br>
        <em>ICDAR</em>, 2023
              <br>
              <a href="https://www.kaggle.com/datasets/reasat/badlad-train/">dataset</a>
        /
              <a href="https://arxiv.org/abs/2303.05325">arXiv</a>
        /
              <a href="https://kaggle.com/c/dlsprint2">competition</a>
              <p></p>
              <p>First Multi-Domain Bengali Document Layout Analysis Dataset, with 700K polygon annotations from image captured documents in the wild.</p>
            </td>
          </tr>




          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/dlsprint.jpg' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://arxiv.org/pdf/2206.14053">
                <papertitle>Bengali Common Voice Speech Dataset for Automatic Speech Recognition</papertitle>
              </a>
              <br>
              <a href="">Samiul Alam</a>,
              <a href="">Asif Sushmit</a>,
              <a href="">Zaowad Abdullah</a>,
              <a href="">Shahrin Nakkhatra</a>,
              <a href="">MD Ansary</a>,
              <a href="">Syed Hossen</a>,
              <a href="">Sazia Mehnaz</a>,
              <a href="">Tahsin Reasat</a>,
              <strong>Ahmed Imtiaz Humayun</strong>
              <br>
        <em>ArXiv</em>, 2022
              <br>
              <a href="https://www.kaggle.com/competitions/dlsprint">competition</a>
        /
              <a href="https://arxiv.org/pdf/2206.14053">arXiv</a>
              <p></p>
              <p>We have crowdsourced the first public 500 hr Bengali Speech Dataset on the Mozilla Common Voice platform, with speech contributed by over 20K people from Bangladesh and India.</p>
            </td>
          </tr>
          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/grapheme.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://www.kaggle.com/c/bengaliai-cv19">
                <papertitle>A Large Multi-Target Dataset of Common Bengali Handwritten Graphemes</papertitle>
              </a>
              <br>
              <a href="">Samiul Alam</a>,
              <a href="">Tahsin Reasat</a>,
              <a href="">Asif Sushmit</a>,
              <a href="">SM Siddiquee</a>,
              <a href="">Fuad Rahman</a>,
              <a href="">Mahady Hasan</a>,
              <strong>Ahmed Imtiaz Humayun</strong>
              <br>
        <em>ICDAR</em>, 2021
              <br>
              <a href="https://www.kaggle.com/c/bengaliai-cv19">competition</a>
        /
              <a href="https://arxiv.org/pdf/2010.00170">arXiv</a>
        /
              <a href="https://www.technology.org/2019/12/31/bengali-ai-handwritten-grapheme-classification/">news</a>
              <p></p>
              <p>A benchmark datset for multi-target classification of handwritten Bengali Graphemes, with novel implications for all alpha-syllabary languages, e.g., Hindi, Gujrati, and Thai.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/numta.gif' width="140">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://www.kaggle.com/c/numta">
                <papertitle>NumtaDB: Assembled Bengali Handwritten Digits</papertitle>
              </a>
              <br>
              <a href="">Samiul Alam</a>,
              <a href="">Tahsin Reasat</a>,
              <a href="">Rashed Doha</a>,
              <strong>Ahmed Imtiaz Humayun</strong>
              <br>
        <em>ArXiv</em>, 2018
              <br>
              <a href="https://www.kaggle.com/c/numta">competition</a>
        /
              <a href="https://arxiv.org/pdf/1806.02452">arXiv</a>
              <p></p>
              <p>The first large scale Multi-Domain Bengali Handwritten Digit Recognition Dataset</p>
            </td>
          </tr>


          </tbody></table>

        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Yet another steal of <a href="https://jonbarron.info/">Jon Barron's</a> amazing website.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
